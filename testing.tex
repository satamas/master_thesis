\chapter{Тестирование}
\section{Тестирование серверного кода}
	Тестирование серверного кода является частью автоматической сборки приложения на TeamCity. Оно производится при помощи библиотеки Junit. В процессе тестирования проверяется что:
\begin{itemize}
\item Сервер корректно транслирует Java код в Котлин
\item Сервер корректно автоматически дополняет код
\item Сервер корректно обнаруживает ошибки в коде.
\item Сервер корректно исполняет код.
\item Сервер выдаёт ошибки при исполнении небезопасного кода.
\item В примерах не содержится ошибок. 
\end{itemize}
	
	Основным преимуществом такого набора тестов является то, что мы можем безопасно обновлять версию Котлина, использующуюся для обработки пользовательских запросов. Так же данные тесты проверяют корректность работы приложения при изменении серверного кода.
	
	Для проверки корректности примеров каждый из них подвергается ряду тестов. Во-первых код примера проверяется сервером на наличие ошибок и предупреждений. Если сервер находит какие-либо ошибки, то это означает, что наш пример устарел из-за обновления Котлина и требуется его обновить. Во-вторых проверяется, что данный пример компилируется и при запуске выдаёт ожидаемый результат. Следует отметить что такие тесты проверяют не только примеры, но и работоспособность самого сервера. 
	
	В качестве дополнительных проверок сервера существует ещё ряд тестовых программ, которые  аналогичным образом проверяются на ошибки и запускаются. При помощи таких программ проверяется ряд особых случаев (использование Kotlin reflection, например), а так же то, что мы корректно реагируем на код, который пытается выполнить небезопасные действия.
	
\section{Нагрузочное тестирование}

	Нагрузочное тестирование вэб приложения это проверка его поведения при большом количестве запросов. Такое тестирование позволяет выявить проблемы, возникающие при этом и оценить максимальное количество пользователей, которое может обслужить данное приложение.
	
	В случае нашего приложения ожидаемым узким местом были запросы на исполнение программы. В рамках нагрузочного тестирования планировалось: 
\begin{itemize}
\item Проверить сервер на наличие других узких мест.
\item Проверить поведение сервера при исполнении особых программ, а именно:
	\begin{itemize}
		\item Исполнение бесконечных программ
		\item Исполнение программ, потребляющих бесконечное количество памяти
		\item Исполнение программ, генерирующих бесконечно большой вывод.
	\end{itemize}
\item Проверить работоспособность автоматического масштабирования
\item Узнать количество пользователей, которые может обслужить одна нода
\item Посмотреть на поведение ноды при подаче на неё большой нагрузки
\end{itemize}

	Всё нагрузочное тестирование проводилось при помощи библиотеки Jmeter.

	Чтобы проверить сервер на наличие узких мест было использовано то, что запросы делятся на несколько типов. Сервер нагружался запросами одного типа и исследовалось его поведение при этом. Так например, для проверки фронтенд сервера, отправлялись запросы на выдачу статического контента и запросы на выдачу примеров.
	
	В результате таких проверок фронтенд сервера получились следующие параметры:
\begin{itemize}
	\item 9 заходов новых пользователей в секунду (т.е. 32000 новых заходов в час) (~200MiB/s bandwidth)
	\item 700 зпросов на загрузку примера в секунду
\end{itemize}
	Данные параметры являются вполне приемлимыми для нашего приложения, а значит фронтенд сервер не является узким местом приложения. 
	
	Ещё одним потенциально узким местом приложения является база данных, но, согласно статистике использования нашего приложения, большинство пользователей не авторизируются, а значит и запросы к базе дынных не отправляют.
	
	Это означает, что единственным узким местом нашего приложения являются бэкенд сервера, поэтому при оценке производительности системы рассматривались исключительно запросы к бэкенд серверу.

	Для того, чтобы оценить количество пользователей, которое может обслужить наше приложение, необходимо было составить модель поведения пользователя. Это было сделано на основе сохранённых записей об активности пользователей на старом сайте kotlin-demo.jetbrains.com. В результате были созданы две модели пользователя:
\begin{itemize}
	\item Активный пользователь -- 13 запросов на проверку ошибок в минуту, 1 запрос на автодополнение в минуту, 1 запрос на исполнение в минуту
	\item Усреднённый пользователь -- 4 запросов на проверку ошибок в минуту, 1 запроса на автодополнение в три минуты, 1 запрос на исполнение в три минуты
\end{itemize}
	
	В результате нагрузочного тестирования бэкенд серверов были получены следующие результаты:
	\begin{itemize}
		\item Одна машина:
		\begin{itemize}
			\item максимум 2.75 запросов на исполнение в секунду;
			\item максимум 110 "активных" пользователей в онлайне
			\item максимум 370 "усреднённых" пользователей в онлайне 
		\end{itemize}
		
		\item Предельная нагрузка на всю систему, приблизительная, при 10 запущенных машинах в бэкенде:
		\begin{itemize}
			\item 3500-4000 пользователей в онлайне;
		\end{itemize} 
	\end{itemize}
	Так же был обнаружен ряд проблем с памятью, возникающих при исполнении программ, генерирующих бесконечный вывод. В последствии данные проблемы были устранены путём введения ограничений на потребляемую память для пользовательских процессов, сервера, а так же докер контейнера в котором всё исполняется.
	
\section{Тестирование клиентского кода}
	Тестирование клиентского кода является важной частью тестирования и при этом, пожалуй, наиболее сложной частью. Сложность подобного тестирования заключается в том, что
\begin{enumerate}
	\item  Для тестирования клиентского кода необходим запущенный сервер или его имитация.
	\item Клиентский код исполняется в браузере, причём в разных браузерах может наблюдаться  различное исполнение кода.
	\item Для полноценного тестирования необходимо тестировать не только код, но и внешний вид приложения и проверять что он не отличается в различных браузерах.
\end{enumerate}

	На данный момент описанные выше проблемы по большому счёту не решены. Имеющееся тестирование клиентского кода заключается в небольшом наборе selenium тестов, которые проверяют корректность подсветки кода, корректность исполнения программ, а так же работу с проектами. Данные тесты требуют запущенного сервера и запускаются внутри браузера firefox, что делает невозможным их запуск в процессе автоматической сборки приложения.
	
	В связи с недостатками имеющегося тестирования и учитывая описанные выше сложности тестирования клиентского кода, сейчас разрабатывается новая система тестов. 
Основой данной системы тестов является программа karma, которая позволяет запускать тесты в различных средах. Это позволит легко запускать тесты на любой машине, т.к. отпадает требование наличия конкретного браузера. Одной из возможных сред является phantomjs, что позволяет запускать тесты на машинах без браузеров вообще, в том числе на агентах сервера сборки приложений. 
	
	